{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Задание 1."
      ],
      "metadata": {
        "id": "aLE17ndnzt2q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ngir3ZpyYgi"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.window import Window"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Инициализация SparkSession\n",
        "spark = SparkSession.builder.appName(\"session_length\").getOrCreate()"
      ],
      "metadata": {
        "id": "uAW51yiRyk2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Исходные данные\n",
        "data = [\n",
        "    ((1, 1562007679), (1, 1562007710), (1, 1562007720), (1, 1562007750)),\n",
        "    ((2, 1564682430), (2, 1564682450), (2, 1564682480))\n",
        "]"
      ],
      "metadata": {
        "id": "XoovPuxjzCyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Преобразование данных в список кортежей\n",
        "rows = []\n",
        "for row in data:\n",
        "    rows.extend([(i[0], i[1]) for i in row])"
      ],
      "metadata": {
        "id": "jpD1iTIIzJ8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание DataFrame\n",
        "columns = [\"id\", \"timestamp\"]\n",
        "df = spark.createDataFrame(rows, columns)"
      ],
      "metadata": {
        "id": "9MoWBgX5zMpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Преобразование timestamp в формат даты\n",
        "df = df.withColumn(\"date\", F.to_date(F.from_unixtime(\"timestamp\")))"
      ],
      "metadata": {
        "id": "4O-xZYByzhre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание окна по id и дате\n",
        "window_spec = Window.partitionBy(\"id\", \"date\").orderBy(\"timestamp\")"
      ],
      "metadata": {
        "id": "qtc8VWgbzkPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Рассчитываем разницу между первым и последним действием в рамках сессии\n",
        "session_length = F.last(\"timestamp\").over(window_spec) - F.first(\"timestamp\").over(window_spec)"
      ],
      "metadata": {
        "id": "6OsBDm_Ezm32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Получаем усредненную длину сессии для каждого id\n",
        "result_df = df.withColumn(\"session_length\", session_length) \\\n",
        "    .groupBy(\"id\") \\\n",
        "    .agg(F.avg(\"session_length\").alias(\"avg_session_length\"))\n",
        "\n",
        "result_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01vP6FEWzqSd",
        "outputId": "a045632a-8761-4c5f-9e04-a93b425b9005"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------------------+\n",
            "| id|avg_session_length|\n",
            "+---+------------------+\n",
            "|  1|             35.75|\n",
            "|  2|23.333333333333332|\n",
            "+---+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Остановка SparkSession\n",
        "spark.stop"
      ],
      "metadata": {
        "id": "9ducDA1D12MA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание 2."
      ],
      "metadata": {
        "id": "oEh96os40GQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import sum as spark_sum, avg as spark_avg, lag, coalesce\n",
        "\n",
        "# Инициализация SparkSession\n",
        "spark = SparkSession.builder\\\n",
        "    .master(\"local[1]\")\\\n",
        "    .appName(\"task_47\")\\\n",
        "    .config(\"spark.executor.memory\", \"10g\")\\\n",
        "    .config(\"spark.executor.cores\", 5)\\\n",
        "    .config(\"spark.dynamicAllocation.enabled\", \"true\")\\\n",
        "    .config(\"spark.dynamicAllocation.maxExecutors\", 5)\\\n",
        "    .config(\"spark.shuffle.service.enabled\", \"true\")\\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "p31yccYAQtWo"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Данные для технических недель\n",
        "week_str_p = (('1', '01.08—06.08'), ('2', '07.08—13.08'), ('3', '14.08—20.08'), ('4', '21.08—27.08'), ('5', '28.08—31.08'))\n",
        "week_str_s = spark.createDataFrame(data=week_str_p, schema=['week', 'week_str'])\n",
        "\n",
        "# Данные о среднедневном спросе\n",
        "demand_p = (('1', '01', 100), ('1', '02', 110), ('2', '01', 120), ('2', '02', 90), ('3', '01', 70), ('3', '02', 80))\n",
        "demand_s = spark.createDataFrame(data=demand_p, schema=['product', 'location', 'demand'])\n",
        "\n",
        "# Данные о складских запасах\n",
        "stock_p = (('1', '01', 1000), ('1', '02', 400), ('2', '01', 300), ('2', '02', 250))\n",
        "stock_s = spark.createDataFrame(data=stock_p, schema=['product', 'location', 'stock'])"
      ],
      "metadata": {
        "id": "tHyiLWwFRnkt"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "week_str_s.createOrReplaceTempView('week_str')\n",
        "demand_s.createOrReplaceTempView('demand')\n",
        "stock_s.createOrReplaceTempView('stock')"
      ],
      "metadata": {
        "id": "SHE7k_ofRp1t"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sql = \"\"\"\n",
        "    with tmp_1 as (\n",
        "        select d.*, coalesce(s.stock, 0) as stock\n",
        "        from demand d\n",
        "        left join stock s using(product, location)\n",
        "    ),\n",
        "\n",
        "    tmp_2 as (\n",
        "        select tmp_1.*, ws.week_str\n",
        "        from tmp_1 cross join week_str ws\n",
        "    ),\n",
        "\n",
        "    tmp_3 as (\n",
        "        select tmp_2.*,\n",
        "            sum(demand) over (partition by product, location, week_str order by location) as total_demand\n",
        "        from tmp_2\n",
        "    ),\n",
        "\n",
        "    tmp_4 as (\n",
        "        select tmp_3.*,\n",
        "            lag(stock - total_demand, 1, 0) over (partition by product, location order by week_str) as closing_stock\n",
        "        from tmp_3\n",
        "    ),\n",
        "\n",
        "    tmp_5 as (\n",
        "        select tmp_4.*,\n",
        "            case\n",
        "                when closing_stock > demand then demand\n",
        "                when closing_stock > 0 and closing_stock <= demand then closing_stock\n",
        "                else 0\n",
        "            end as sales\n",
        "        from tmp_4\n",
        "    ),\n",
        "\n",
        "    tmp_6 as (\n",
        "        select tmp_5.*,\n",
        "            min(closing_stock) over (partition by product, location, week_str) as stock_at_end\n",
        "        from tmp_5\n",
        "    )\n",
        "\n",
        "    select\n",
        "        tmp_6.week_str,\n",
        "        tmp_6.product,\n",
        "        tmp_6.location,\n",
        "        sum(tmp_6.sales) as sales,\n",
        "        avg(tmp_6.stock_at_end) as stock_at_end\n",
        "    from tmp_6\n",
        "    group by tmp_6.week_str, tmp_6.product, tmp_6.location\n",
        "    order by 1, 2, 3\n",
        "\"\"\"\n",
        "\n",
        "# Выполнение запроса и вывод результатов\n",
        "result_df = spark.sql(sql)\n",
        "result_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7XJV0LpRtT3",
        "outputId": "a9bfc379-4beb-4d4b-d7bb-fb59bdc4eda7"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+--------+-----+------------+\n",
            "|week_str   |product|location|sales|stock_at_end|\n",
            "+-----------+-------+--------+-----+------------+\n",
            "|01.08—06.08|1      |01      |0    |0.0         |\n",
            "|01.08—06.08|1      |02      |0    |0.0         |\n",
            "|01.08—06.08|2      |01      |0    |0.0         |\n",
            "|01.08—06.08|2      |02      |0    |0.0         |\n",
            "|01.08—06.08|3      |01      |0    |0.0         |\n",
            "|01.08—06.08|3      |02      |0    |0.0         |\n",
            "|07.08—13.08|1      |01      |100  |900.0       |\n",
            "|07.08—13.08|1      |02      |110  |290.0       |\n",
            "|07.08—13.08|2      |01      |120  |180.0       |\n",
            "|07.08—13.08|2      |02      |90   |160.0       |\n",
            "|07.08—13.08|3      |01      |0    |-70.0       |\n",
            "|07.08—13.08|3      |02      |0    |-80.0       |\n",
            "|14.08—20.08|1      |01      |100  |900.0       |\n",
            "|14.08—20.08|1      |02      |110  |290.0       |\n",
            "|14.08—20.08|2      |01      |120  |180.0       |\n",
            "|14.08—20.08|2      |02      |90   |160.0       |\n",
            "|14.08—20.08|3      |01      |0    |-70.0       |\n",
            "|14.08—20.08|3      |02      |0    |-80.0       |\n",
            "|21.08—27.08|1      |01      |100  |900.0       |\n",
            "|21.08—27.08|1      |02      |110  |290.0       |\n",
            "+-----------+-------+--------+-----+------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Остановка SparkSession\n",
        "spark.stop"
      ],
      "metadata": {
        "id": "GT9yoHM5RvxT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
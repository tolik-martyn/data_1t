{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "OBZ92-O1kwi5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import findspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import *"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. С помощью модуля pandas преобразуйте файл из .xlsx в .csv формат"
      ],
      "metadata": {
        "id": "KXVl3C21rdST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Путь к файлу Excel\n",
        "pathFile = '/content/online_retail.xlsx'"
      ],
      "metadata": {
        "id": "_QRxNO89k4E8"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка файла\n",
        "df = pd.read_excel(pathFile)"
      ],
      "metadata": {
        "id": "X58T5VksoSkn"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Путь для сохранения файла CSV\n",
        "pathCSV = '/content/online_retail.csv'"
      ],
      "metadata": {
        "id": "cNISIhQroTGk"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Сохранение DataFrame в формате CSV\n",
        "df.to_csv(pathCSV, sep=\";\", index=False)"
      ],
      "metadata": {
        "id": "5dG8qb3vogGj"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Инициализируйте Spark-сессию"
      ],
      "metadata": {
        "id": "1EL9QqEZro9_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Инициализация Spark и создание сессии\n",
        "findspark.init()\n",
        "spark = SparkSession.builder.master(\"local[1]\").appName(\"task_47\").config(\"spark.executor.memory\", \"10g\")\\\n",
        "    .config(\"spark.executor.cores\", 5).config(\"spark.dynamicAllocation.enabled\", \"true\")\\\n",
        "    .config(\"spark.dynamicAllocation.maxExecutors\", 5).config(\"spark.shuffle.service.enabled\", \"true\").getOrCreate()"
      ],
      "metadata": {
        "id": "DUvTmqt9qK49"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Определение схемы данных\n",
        "data_schema = [\n",
        "    StructField('InvoiceNo', StringType(), True),\n",
        "    StructField('StockCode', StringType(), True),\n",
        "    StructField('Description', StringType(), True),\n",
        "    StructField('Quantity', IntegerType(), True),\n",
        "    StructField('InvoiceDate', DateType(), True),\n",
        "    StructField('UnitPrice', DoubleType(), True),\n",
        "    StructField('CustomerID', StringType(), True),\n",
        "    StructField('Country', StringType(), True),\n",
        "]\n",
        "final_struc = StructType(fields=data_schema)"
      ],
      "metadata": {
        "id": "7o7fafMQqajv"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Создайте dataframe из скачанного файла"
      ],
      "metadata": {
        "id": "nyBDkRyIrx9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Чтение файла CSV в DataFrame\n",
        "dfs = spark.read.csv(pathCSV, sep=\";\", header=True, schema=final_struc)"
      ],
      "metadata": {
        "id": "zTCiziERqxQT"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Подсчитайте следующие показатели:"
      ],
      "metadata": {
        "id": "fsWS2L-Ir-B6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### a. Количество строк в файле"
      ],
      "metadata": {
        "id": "a4OowIp1sFX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Подсчет количества строк в DataFrame\n",
        "row_count = dfs.count()\n",
        "print(f\"Количество строк в файле: {row_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMnh83WfsMXL",
        "outputId": "02ad5c97-d863-40fc-ae00-008b378761db"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество строк в файле: 541909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### b. Количество уникальных клиентов"
      ],
      "metadata": {
        "id": "Qjk_hhbRskN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Подсчет количества уникальных клиентов\n",
        "unique_customers_count = dfs.select('CustomerID').distinct().count()\n",
        "print(f\"Количество уникальных клиентов: {unique_customers_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k95IWO82shbB",
        "outputId": "a8cdd93f-579a-484f-c649-b2c283af9ec9"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество уникальных клиентов: 4373\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### c. В какой стране совершается большинство покупок"
      ],
      "metadata": {
        "id": "-BYXmH2ItPtH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import desc\n",
        "\n",
        "# Группировка данных по стране и подсчет количества покупок в каждой стране\n",
        "purchase_count_by_country = dfs.groupBy('Country').count()\n",
        "\n",
        "# Нахождение страны с наибольшим количеством покупок\n",
        "most_purchases_country = purchase_count_by_country.orderBy(desc('count')).first()['Country']\n",
        "\n",
        "print(f\"Страна с наибольшим количеством покупок: {most_purchases_country}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2oFy97dtUKW",
        "outputId": "0028449b-5be4-45d3-ad19-a6159eb10f06"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Страна с наибольшим количеством покупок: United Kingdom\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### d. Даты самой ранней и самой последней покупки на платформе"
      ],
      "metadata": {
        "id": "8vzs8qy5uja2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import min, max\n",
        "\n",
        "# Нахождение самой ранней и самой последней даты покупки\n",
        "earliest_date = dfs.select(min('InvoiceDate')).first()[0]\n",
        "latest_date = dfs.select(max('InvoiceDate')).first()[0]\n",
        "\n",
        "print(f\"Самая ранняя дата покупки: {earliest_date}\")\n",
        "print(f\"Самая последняя дата покупки: {latest_date}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNWZdUYHtkhi",
        "outputId": "77cb2ebd-c033-4dc5-ffda-07f42d4d707e"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Самая ранняя дата покупки: 2010-12-01\n",
            "Самая последняя дата покупки: 2011-12-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Проведите RFM-анализ клиентов платформы"
      ],
      "metadata": {
        "id": "QJy7dpyCu3kv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### a. Recency - Давность: как давно каждый покупатель совершил покупку"
      ],
      "metadata": {
        "id": "HHumhxqCwZD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import current_date, expr\n",
        "\n",
        "# Создание временного представления\n",
        "dfs.createOrReplaceTempView(\"online_retail_view\")"
      ],
      "metadata": {
        "id": "tSYYqlBTu5Dv"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Расчет Recency\n",
        "recency_query = \"\"\"\n",
        "    SELECT\n",
        "        CustomerID,\n",
        "        DATEDIFF(current_date(), MAX(InvoiceDate)) AS Recency\n",
        "    FROM\n",
        "        online_retail_view\n",
        "    GROUP BY\n",
        "        CustomerID\n",
        "\"\"\"\n",
        "\n",
        "recency_result = spark.sql(recency_query)\n",
        "recency_result.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWvYSBVWwMT8",
        "outputId": "54b010b4-a87e-44b3-88ab-bbe930d01bea"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------+\n",
            "|CustomerID|Recency|\n",
            "+----------+-------+\n",
            "|   15039.0|   4370|\n",
            "|   16553.0|   4524|\n",
            "|   13178.0|   4387|\n",
            "|   17786.0|   4446|\n",
            "|   12891.0|   4546|\n",
            "+----------+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### b. Frequency- Частота: Как часто они что-то покупали"
      ],
      "metadata": {
        "id": "H0ED6clBw6NK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Расчет Frequency\n",
        "frequency_query = \"\"\"\n",
        "    SELECT\n",
        "        CustomerID,\n",
        "        COUNT(InvoiceNo) AS Frequency\n",
        "    FROM\n",
        "        online_retail_view\n",
        "    GROUP BY\n",
        "        CustomerID\n",
        "\"\"\"\n",
        "\n",
        "frequency_result = spark.sql(frequency_query)\n",
        "frequency_result.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MIL7a0cw8jg",
        "outputId": "657b2e4f-98fb-4c31-f5eb-46f7f9929676"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------+\n",
            "|CustomerID|Frequency|\n",
            "+----------+---------+\n",
            "|   15039.0|     1508|\n",
            "|   16553.0|       86|\n",
            "|   13178.0|      265|\n",
            "|   17786.0|       72|\n",
            "|   12891.0|        3|\n",
            "+----------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### c. Monetary - Денежная ценность: сколько денег они в среднем тратят при совершении покупок"
      ],
      "metadata": {
        "id": "K4HMCq-OxVhs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Расчет Monetary\n",
        "monetary_query = \"\"\"\n",
        "    SELECT\n",
        "        CustomerID,\n",
        "        AVG(Quantity * UnitPrice) AS Monetary\n",
        "    FROM\n",
        "        online_retail_view\n",
        "    GROUP BY\n",
        "        CustomerID\n",
        "\"\"\"\n",
        "\n",
        "monetary_result = spark.sql(monetary_query)\n",
        "monetary_result.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fyh99WKxYAa",
        "outputId": "e4c4a58b-3a35-4adb-c53b-28b9da3f393e"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------------+\n",
            "|CustomerID|          Monetary|\n",
            "+----------+------------------+\n",
            "|   15039.0|13.120981432360722|\n",
            "|   16553.0|  65.8670930232558|\n",
            "|   13178.0| 21.60554716981133|\n",
            "|   17786.0| 3.871388888888889|\n",
            "|   12891.0|110.33333333333333|\n",
            "+----------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Добавьте в dataframe для каждого клиента 3 новых поля"
      ],
      "metadata": {
        "id": "Dl-CxP3azeEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "# 1. Добавление новых полей\n",
        "df_with_rfm = dfs.groupBy(\"CustomerID\") \\\n",
        "    .agg(\n",
        "        F.max(\"InvoiceDate\").alias(\"LastPurchaseDate\"),\n",
        "        F.countDistinct(\"InvoiceNo\").alias(\"Frequency\"),\n",
        "        F.avg(F.expr(\"Quantity * UnitPrice\")).alias(\"Monetary\")\n",
        "    ) \\\n",
        "    .withColumn(\"Recency\", F.datediff(F.current_date(), F.col(\"LastPurchaseDate\")).cast(IntegerType()))\n"
      ],
      "metadata": {
        "id": "gaNe_dEsxmed"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Разбиение клиентов на группы для каждого показателя\n",
        "# Recency\n",
        "window_spec_recency = Window.orderBy(\"Recency\")\n",
        "df_with_rfm = df_with_rfm.withColumn(\"RecencyGroup\", F.ntile(3).over(window_spec_recency))\n",
        "\n",
        "# Frequency\n",
        "window_spec_frequency = Window.orderBy(F.col(\"Frequency\").desc())\n",
        "df_with_rfm = df_with_rfm.withColumn(\"FrequencyGroup\", F.ntile(3).over(window_spec_frequency))\n",
        "\n",
        "# Monetary\n",
        "window_spec_monetary = Window.orderBy(F.col(\"Monetary\").desc())\n",
        "df_with_rfm = df_with_rfm.withColumn(\"MonetaryGroup\", F.ntile(3).over(window_spec_monetary))"
      ],
      "metadata": {
        "id": "W23HWsGLzoy2"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Добавление итогового столбца с \"суммой\" значений групп\n",
        "df_with_rfm = df_with_rfm.withColumn(\"TotalGroup\",\n",
        "    F.concat(F.col(\"RecencyGroup\").cast(\"string\"),\n",
        "             F.col(\"FrequencyGroup\").cast(\"string\"),\n",
        "             F.col(\"MonetaryGroup\").cast(\"string\")))"
      ],
      "metadata": {
        "id": "reffFXsp0YK4"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Сохранение только клиентов с группой \"AAA\" в отдельный CSV-файл\n",
        "df_filtered = df_with_rfm.filter(\"TotalGroup = '111'\")\n",
        "df_filtered.write.csv('/content/filtered_customers.csv', header=True, mode='overwrite')"
      ],
      "metadata": {
        "id": "WfYX89za0YqC"
      },
      "execution_count": 66,
      "outputs": []
    }
  ]
}